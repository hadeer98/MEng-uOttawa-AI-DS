# Chinese Sign Language Image Classification
**Abstract**— Sign language is the easiest form of communication for people who have trouble hearing. Sign language recognition is an important task when it comes to converting sign language into text. The current sign language recognition methods are broadly divided into two types: the traditional machine learning method using image features and the deep neural network-based method. The following aspects best describe the primary contributions of this study. The training and testing of the ResNet model were done by combining different feature engineering techniques. The training data represents the baseline for the classification task, and the test data is the result of fine-tuning the pre-trained model with some hidden layers to make it more accurate. In summary after applying several classification models which are linear SVM, RBF kernel SVM, Random Forest, MLP, Naïve Bayes, and XGBoost. The best model was MLP with a test accuracy of 63% and after applying hyperparameter tuning it became 64%.<br>
<br>
For more details please read the **Conference IEEE Paper** format report: https://github.com/Sa2a/CV_Hand_Gestures/blob/main/Reports/Conference%20IEEE%20Paper.pdf
<br> Or the **Poster Presentation**: https://github.com/Sa2a/CV_Hand_Gestures/blob/main/Reports/Poster%20presentation.pdf
